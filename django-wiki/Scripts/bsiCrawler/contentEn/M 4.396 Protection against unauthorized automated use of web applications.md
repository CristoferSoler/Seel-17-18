#M 4.396 Protection against unauthorized automated use of web applications
Responsible for initiation: IT security officer, IT manager

Responsible for implementation: Developer, Administrator

A web application is typically used by humans and thus does not require automated usage (eg, through scripts). Brute force attacks (eg guessing access data) and enumeration attacks (eg automated detection of valid login names) are based on the automated control of a web application (automation). These attacks typically attempt to collect sensitive data through repetitive, slightly varying queries (such as changed usernames).

To prevent automation and prevent associated attacks, the web application must be able to distinguish automated from manual access. Automated attacks are characterized by a high number of access attempts within a short period of time, which significantly exceeds the usual measure.

Therefore, a tolerance threshold for repeatedly retrieved resources can make such attacks more difficult (tar pit). If limits are set against automated queries, care must be taken to ensure that legitimate users are not restricted as much as possible in the functionality and operation of the web application. If Web application primitive limits are too tight, attackers can abuse it at the Web application level for denial-of-service attacks. For example, if user accounts are blocked for a certain amount of time after a specified number of unsuccessful login attempts, targeted incorrect entries may result in a longer-term lockdown of many user accounts. As a result, legitimate users will no longer be able to log in to the web application during this time.

In addition, the efficiency of automated attacks is usually highly dependent on the level of detail of the information in the web application's return responses (see M 4.400 Restricting Security Information Releases for Web Applications and Web Services).

The following examples give hints on possible protection mechanisms:

* An artificial delay between entering user authentication credentials and reporting a failed login attempt can complicate brute-force attacks due to increased time requirements. The effectiveness of this method can be increased by a progressive increase in the delay after each failed attempt.
* If entries are rejected, information about the cause should be written generically. For example, an attacker may not be able to log in to a valid user account because of notifications such as invalid password instead of access data (see also M 4.395 Error Handling by Web Applications and Web Services). ,
* Attack attempts are often characterized by multiple failed attempts when performing an action. Therefore, an existing session should be terminated if an unusually high number of failed attempts are identified, and then a re-login is required.
* Automated attacks can be averted by temporarily blocking the IP address if an attack is suspected. It should be kept in mind that this measure may also affect bystanders who are not involved (eg if multiple users use the same proxy).
* Frequently, so-called CAPTCHAs (Completely Automated Public Turing Test To Tell Computer and Humans Apart) are used to distinguish automated and manual access. In this case, the user of the web application must solve tasks (for example, the characters in an image must be recognized and tapped or questions answered), which is not possible for a computer program without further ado is. Depending on the technology used and the task, the web application may only be used to a limited extent for people with disabilities. So should z. B. as an alternative to fading in the task, they can also be made available acoustically to enable visually impaired people to use the web application. It should be noted that the use of CAPTCHAs for reasons of discrimination is regulated or prohibited by law in many countries. In Germany, the Federal Administration is obliged to design its publicly accessible Internet and Intranet offers according to the Barrier-Free Information Technology Ordinance (BITV).




